{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0393fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03d399e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('3Di_3Dn', '-10.0', '-0.5', '0.6')\n",
      "('3Di_3Dn', '-6.0', '-0.5', '0.6')\n",
      "('3Di_3Dn', '-8.0', '-0.5', '0.6')\n",
      "('3Di_3Dn_aa', '-2.0', '-0.5', '0.4', '0.2', '0.4')\n",
      "('3Di_3Dn_aa', '-4.0', '-0.5', '0.4', '0.2', '0.4')\n",
      "('3Di_3Dn_aa', '-4.0', '-0.5', '0.4', '0.3', '0.3')\n",
      "('3Di_3Dn_aa', '-4.0', '-0.5', '0.5', '0.2', '0.3')\n",
      "('3Di_3Dn_aa', '-4.0', '-0.5', '0.6', '0.2', '0.2')\n",
      "('3Di_3Dn_aa', '-6.0', '-0.5', '0.3', '0.3', '0.4')\n",
      "('3Di_3Dn_aa', '-6.0', '-0.5', '0.4', '0.2', '0.4')\n",
      "('3Di_3Dn_aa', '-6.0', '-0.5', '0.4', '0.3', '0.3')\n",
      "('3Di_3Dn_aa', '-6.0', '-0.5', '0.5', '0.2', '0.3')\n",
      "('3Di_3Dn_aa', '-6.0', '-0.5', '0.5', '0.3', '0.2')\n",
      "('3Di_3Dn_aa', '-6.0', '-0.5', '0.6', '0.2', '0.2')\n",
      "('3Di_3Dn_aa', '-8.0', '-0.5', '0.4', '0.3', '0.3')\n",
      "('3Di_3Dn_aa', '-8.0', '-0.5', '0.5', '0.3', '0.2')\n",
      "('aa_3Dn', '-4.0', '-0.5', '0.6')\n",
      "('aa_3Dn', '-6.0', '-0.5', '0.6')\n",
      "('aa_3Dn', '-8.0', '-0.5', '0.4')\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary to store the data\n",
    "results_dict = {}\n",
    "validity_dict = {}\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('val_results_SUTTFFP_combo.txt', 'r') as file:\n",
    "    # Read lines in chunks of three\n",
    "    while True:\n",
    "        # Read the next three lines\n",
    "        line1 = file.readline().strip()\n",
    "        line2 = file.readline().strip()\n",
    "        line3 = file.readline().strip()\n",
    "        \n",
    "        # Break the loop if EOF is reached\n",
    "        if not line3:\n",
    "            break\n",
    "        \n",
    "        # Extract key components from the first line\n",
    "        # Format: Processing val_search/MI/MI_-6.0_-1.5_config_results\n",
    "        #print(parts)\n",
    "        parts = line1.split('/')\n",
    "        identifier = parts[1]  # Extract 'MI'\n",
    "        if parts[2].split('_')[2] ==\"aa\":\n",
    "            config = parts[2].split('_')[-7:-2]\n",
    "            key = (identifier, config[0],config[1],config[2],config[3],config[4])\n",
    "\n",
    "        else: \n",
    "            config = parts[2].split('_')[-5:-2]\n",
    "            key = (identifier, config[0],config[1],config[2])\n",
    "        print(key)\n",
    "        # Extract the values from the third line\n",
    "        values = tuple(map(float, line3.split()))\n",
    "        \n",
    "        # Add to the dictionary\n",
    "        results_dict[key] = values\n",
    "        \n",
    "        # Check if the second line contains \"93\" and add to the validity dictionary\n",
    "        is_valid = '93.00' in line2\n",
    "        validity_dict[key] = is_valid\n",
    "\n",
    "# Print the resulting dictionary\n",
    "#print(results_dict)\n",
    "#print(validity_dict)\n",
    "print(len(results_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd67de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3Di_3Dn\n",
      "0.9045, 0.6977, 0.2027, ['-10.0', '-0.5', '0.6', True]\n",
      "0.8990, 0.6975, 0.2076, ['-6.0', '-0.5', '0.6', True]\n",
      "0.9004, 0.6947, 0.2060, ['-8.0', '-0.5', '0.6', True]\n",
      "3Di_3Dn_aa\n",
      "0.9315, 0.7271, 0.2054, ['-2.0', '-0.5', '0.4', '0.2', '0.4', True]\n",
      "0.9011, 0.7094, 0.2178, ['-4.0', '-0.5', '0.4', '0.3', '0.3', True]\n",
      "0.9139, 0.7060, 0.2229, ['-4.0', '-0.5', '0.4', '0.2', '0.4', True]\n",
      "0.9047, 0.7020, 0.2060, ['-4.0', '-0.5', '0.6', '0.2', '0.2', True]\n",
      "0.9093, 0.7016, 0.2114, ['-4.0', '-0.5', '0.5', '0.2', '0.3', True]\n",
      "0.8997, 0.6989, 0.2083, ['-8.0', '-0.5', '0.4', '0.3', '0.3', True]\n",
      "0.9076, 0.6961, 0.2060, ['-8.0', '-0.5', '0.5', '0.3', '0.2', True]\n",
      "0.9117, 0.6948, 0.2159, ['-6.0', '-0.5', '0.5', '0.2', '0.3', True]\n",
      "0.9086, 0.6931, 0.2162, ['-6.0', '-0.5', '0.6', '0.2', '0.2', True]\n",
      "0.9045, 0.6924, 0.1996, ['-6.0', '-0.5', '0.4', '0.2', '0.4', True]\n",
      "0.9095, 0.6888, 0.2099, ['-6.0', '-0.5', '0.5', '0.3', '0.2', True]\n",
      "0.8958, 0.6885, 0.1990, ['-6.0', '-0.5', '0.4', '0.3', '0.3', True]\n",
      "0.9043, 0.6875, 0.1942, ['-6.0', '-0.5', '0.3', '0.3', '0.4', True]\n",
      "aa_3Dn\n",
      "0.8793, 0.6200, 0.1497, ['-6.0', '-0.5', '0.6', True]\n",
      "0.8818, 0.6167, 0.1527, ['-8.0', '-0.5', '0.4', True]\n",
      "0.8760, 0.6147, 0.1564, ['-4.0', '-0.5', '0.6', True]\n"
     ]
    }
   ],
   "source": [
    "best_by_method = {}\n",
    "best_params_by_method = {}\n",
    "results_by_method_dict = {}\n",
    "# Iterate over the results dictionary\n",
    "for key, val in results_dict.items():\n",
    "   # if validity_dict[key]:\n",
    "    first_entry = key[0]  # Extract the first part of the key (e.g., 'MI')\n",
    "    if first_entry not in results_by_method_dict:\n",
    "        results_by_method_dict[first_entry] = []\n",
    "    results_by_method_dict[first_entry].append(list(val) + list(key)[1:] + [validity_dict[key]])  # Collect val[0] for this first entry\n",
    "\n",
    "for key, triples in results_by_method_dict.items():\n",
    "    print(key)\n",
    "    sorted_triples = sorted(triples, key=lambda x: x[1], reverse = True)\n",
    "\n",
    "    # Print each triple with values rounded to the 4th decimal\n",
    "    for triple in sorted_triples:\n",
    "        print(f\"{round(triple[0], 4):.4f}, {round(triple[1], 4):.4f}, {round(triple[2], 4):.4f}, {triple[3:]}\")\n",
    "    best_by_method[key]=tuple(sorted_triples[0][:3])\n",
    "    best_params_by_method[key] = tuple(sorted_triples[0][3:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2893157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        3Di_3Dn 0.9045, 0.6977, 0.2027\n",
      "     3Di_3Dn_aa 0.9315, 0.7271, 0.2054\n",
      "         aa_3Dn 0.8793, 0.6200, 0.1497\n"
     ]
    }
   ],
   "source": [
    "for key,triple in best_by_method.items():\n",
    "    print(f\"{key:>15} {round(triple[0], 4):.4f}, {round(triple[1], 4):.4f}, {round(triple[2], 4):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d7dec10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3Di_3Dn': ('-10.0', '-0.5', '0.6'),\n",
       " '3Di_3Dn_aa': ('-2.0', '-0.5', '0.4', '0.2', '0.4'),\n",
       " 'aa_3Dn': ('-6.0', '-0.5', '0.6')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_by_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823f9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldseek default\n",
    "best_params_by_method[\"3Di_aa\"] = ('-10.0','-1.0','2.1','1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44e947",
   "metadata": {},
   "source": [
    "## Write config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "114715f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.0 -0.5 0.6\n",
      "-6.0 -0.5 0.6\n"
     ]
    }
   ],
   "source": [
    "# for two alphabets\n",
    "name = {}\n",
    "name[\"3Di\"] = \"3Di\"\n",
    "name[\"aa\"] = \"aa\"\n",
    "name[\"3Dn\"] = \"graph_clusters\"\n",
    "\n",
    "data_path = \"/cluster/tufts/pettilab/shared/structure_comparison_data\"\n",
    "ref_path =f\"protein_data/ref_names.csv\"\n",
    "query_list_dir_path = f\"protein_data/test_queries_by_10\"\n",
    "coord_path = \"protein_data/allCACoord.npz\"\n",
    "for alphabet,val in best_params_by_method.items():\n",
    "    if alphabet == \"3Di_3Dn_aa\": continue\n",
    "    a1, a2 = alphabet.split('_')\n",
    "    a1 = name[a1]\n",
    "    a2 = name[a2]\n",
    "    p1 = pickle.load(open(f\"{data_path}/alphabets/{a1}_karlin_params.pkl\", \"rb\"))\n",
    "    p2 = pickle.load(open(f\"{data_path}/alphabets/{a2}_karlin_params.pkl\", \"rb\"))\n",
    "    \n",
    "    if alphabet!= \"3Di_aa\":\n",
    "        go,ge,w1 = val\n",
    "        print(go,ge,w1)\n",
    "        w2=1-float(w1)\n",
    "    else:\n",
    "        go,ge,w1, w2 = val\n",
    "    path_to_config = f\"test_search_combos/{alphabet}_{go}_{ge}_{w1}_config\"\n",
    "    with open(path_to_config, 'w') as file:\n",
    "        file.write(f\"data_path: {data_path}\" + '\\n')\n",
    "        file.write(f\"coord_d: {coord_path}\" + '\\n')\n",
    "        file.write(f\"oh_d1: alphabets/{a1}.npz\" +'\\n')\n",
    "        file.write(f\"blosum1: alphabets/{a1}_blosum.npy\" +'\\n')\n",
    "        file.write(f\"oh_d2: alphabets/{a2}.npz\" +'\\n')\n",
    "        file.write(f\"blosum2: alphabets/{a2}_blosum.npy\" +'\\n')\n",
    "        file.write(f\"gap_open: {go}\" + '\\n')\n",
    "        file.write(f\"gap_extend: {ge}\" + '\\n')\n",
    "        file.write(f\"w1: {w1}\" + '\\n')\n",
    "        file.write(f\"w2: {w2}\" + '\\n')\n",
    "        file.write(f\"use_two: True\" + '\\n')\n",
    "        file.write(f\"lam: {p1[\"lam\"]}\" + '\\n')\n",
    "        file.write(f\"k: {p1[\"k\"]}\" + '\\n')\n",
    "        file.write(f\"lam2: {p2[\"lam\"]}\" + '\\n')\n",
    "        file.write(f\"k2: {p2[\"k\"]}\" + '\\n')\n",
    "        file.write(f\"refs: {ref_path}\"+ '\\n')\n",
    "        file.write(f\"query_list_dir: {query_list_dir_path}\"+ '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c73fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for three alphabets\n",
    "ref_path =f\"protein_data/ref_names.csv\"\n",
    "query_list_dir_path = f\"protein_data/test_queries_by_10\"\n",
    "coord_path = \"protein_data/allCACoord.npz\"\n",
    "alphabet = \"3Di_3Dn_aa\"\n",
    "a1, a2, a3 = alphabet.split('_')\n",
    "a1 = name[a1]\n",
    "a2 = name[a2]\n",
    "a3 = name[a3]\n",
    "p1 = pickle.load(open(f\"{data_path}/alphabets/{a1}_karlin_params.pkl\", \"rb\"))\n",
    "p2 = pickle.load(open(f\"{data_path}/alphabets/{a2}_karlin_params.pkl\", \"rb\"))\n",
    "p3 = pickle.load(open(f\"{data_path}/alphabets/{a3}_karlin_params.pkl\", \"rb\"))\n",
    "\n",
    "go,ge,w1,w2,w3 = best_params_by_method[alphabet]\n",
    "path_to_config = f\"test_search_combos/{alphabet}_{go}_{ge}_{w1}_{w2}_{w3}_config\"\n",
    "with open(path_to_config, 'w') as file:\n",
    "    file.write(f\"data_path: {data_path}\" + '\\n')\n",
    "    file.write(f\"coord_d: {coord_path}\" + '\\n')\n",
    "    file.write(f\"oh_d1: alphabets/{a1}.npz\" +'\\n')\n",
    "    file.write(f\"blosum1: alphabets/{a1}_blosum.npy\" +'\\n')\n",
    "    file.write(f\"oh_d2: alphabets/{a2}.npz\" +'\\n')\n",
    "    file.write(f\"blosum2: alphabets/{a2}_blosum.npy\" +'\\n')\n",
    "    file.write(f\"oh_d3: alphabets/{a3}.npz\" +'\\n')\n",
    "    file.write(f\"blosum3: alphabets/{a3}_blosum.npy\" +'\\n')\n",
    "    file.write(f\"gap_open: {go}\" + '\\n')\n",
    "    file.write(f\"gap_extend: {ge}\" + '\\n')\n",
    "    file.write(f\"w1: {w1}\" + '\\n')\n",
    "    file.write(f\"w2: {w2}\" + '\\n')\n",
    "    file.write(f\"w3: {w3}\" + '\\n')\n",
    "    file.write(f\"use_three: True\" + '\\n')\n",
    "    file.write(f\"lam: {p1[\"lam\"]}\" + '\\n')\n",
    "    file.write(f\"k: {p1[\"k\"]}\" + '\\n')\n",
    "    file.write(f\"lam2: {p2[\"lam\"]}\" + '\\n')\n",
    "    file.write(f\"k2: {p2[\"k\"]}\" + '\\n')\n",
    "    file.write(f\"lam3: {p3[\"lam\"]}\" + '\\n')\n",
    "    file.write(f\"k3: {p3[\"k\"]}\" + '\\n')\n",
    "    file.write(f\"refs: {ref_path}\"+ '\\n')\n",
    "    file.write(f\"query_list_dir: {query_list_dir_path}\"+ '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c5053",
   "metadata": {},
   "source": [
    "## Repeat for dihedral combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d7b7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('3Di_3Dn_dihedral', '-10.0', '-0.5', '0.5', '0.3', '0.2')\n",
      "('3Di_3Dn_dihedral', '-4.0', '-0.5', '0.3', '0.2', '0.5')\n",
      "('3Di_3Dn_dihedral', '-4.0', '-0.5', '0.4', '0.2', '0.4')\n",
      "('3Di_3Dn_dihedral', '-4.0', '-0.5', '0.4', '0.3', '0.3')\n",
      "('3Di_3Dn_dihedral', '-4.0', '-0.5', '0.5', '0.2', '0.3')\n",
      "('3Di_3Dn_dihedral', '-4.0', '-0.5', '0.5', '0.3', '0.2')\n",
      "('3Di_3Dn_dihedral', '-6.0', '-0.5', '0.3', '0.2', '0.5')\n",
      "('3Di_3Dn_dihedral', '-6.0', '-0.5', '0.5', '0.2', '0.3')\n",
      "('3Di_3Dn_dihedral', '-6.0', '-0.5', '0.6', '0.2', '0.2')\n",
      "('3Di_3Dn_dihedral', '-8.0', '-0.5', '0.4', '0.3', '0.3')\n",
      "('3Di_3Dn_dihedral', '-8.0', '-0.5', '0.5', '0.3', '0.2')\n",
      "('3Di_3Dn_dihedral', '-8.0', '-0.5', '0.6', '0.2', '0.2')\n",
      "('dihedral_3Di', '-10.0', '-0.5', '0.3')\n",
      "('dihedral_3Di', '-10.0', '-0.5', '0.4')\n",
      "('dihedral_3Di', '-12.0', '-0.5', '0.3')\n",
      "('dihedral_3Di', '-6.0', '-0.5', '0.4')\n",
      "('dihedral_3Di', '-8.0', '-0.5', '0.3')\n",
      "('dihedral_3Di', '-8.0', '-0.5', '0.4')\n",
      "('dihedral_3Di', '-8.0', '-1.0', '0.3')\n",
      "('dihedral_3Dn', '-2.0', '-0.5', '0.7')\n",
      "('dihedral_3Dn', '-4.0', '-0.5', '0.6')\n",
      "('dihedral_3Dn', '-4.0', '-0.5', '0.7')\n",
      "('dihedral_3Dn', '-6.0', '-0.5', '0.6')\n",
      "('dihedral_3Dn', '-6.0', '-0.5', '0.7')\n",
      "('dihedral_3Dn', '-8.0', '-0.5', '0.6')\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary to store the data\n",
    "results_dict = {}\n",
    "validity_dict = {}\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('val_results_SUTTFFP_combo_with_dihedral.txt', 'r') as file:\n",
    "    # Read lines in chunks of three\n",
    "    while True:\n",
    "        # Read the next three lines\n",
    "        line1 = file.readline().strip()\n",
    "        line2 = file.readline().strip()\n",
    "        line3 = file.readline().strip()\n",
    "        \n",
    "        # Break the loop if EOF is reached\n",
    "        if not line3:\n",
    "            break\n",
    "        \n",
    "        # Extract key components from the first line\n",
    "        # Format: Processing val_search/MI/MI_-6.0_-1.5_config_results\n",
    "        #print(parts)\n",
    "        parts = line1.split('/')\n",
    "        identifier = parts[1]  # Extract 'MI'\n",
    "        if parts[2].split('_')[2] ==\"dihedral\":\n",
    "            config = parts[2].split('_')[-7:-2]\n",
    "            key = (identifier, config[0],config[1],config[2],config[3],config[4])\n",
    "\n",
    "        else: \n",
    "            config = parts[2].split('_')[-5:-2]\n",
    "            key = (identifier, config[0],config[1],config[2])\n",
    "        print(key)\n",
    "        # Extract the values from the third line\n",
    "        values = tuple(map(float, line3.split()))\n",
    "        \n",
    "        # Add to the dictionary\n",
    "        results_dict[key] = values\n",
    "        \n",
    "        # Check if the second line contains \"93\" and add to the validity dictionary\n",
    "        is_valid = '93.00' in line2\n",
    "        validity_dict[key] = is_valid\n",
    "\n",
    "# Print the resulting dictionary\n",
    "#print(results_dict)\n",
    "#print(validity_dict)\n",
    "print(len(results_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "433ada44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3Di_3Dn_dihedral\n",
      "0.9137, 0.7180, 0.2123, ['-4.0', '-0.5', '0.4', '0.3', '0.3', True]\n",
      "0.9055, 0.7079, 0.2150, ['-4.0', '-0.5', '0.5', '0.2', '0.3', True]\n",
      "0.9158, 0.7067, 0.2056, ['-4.0', '-0.5', '0.4', '0.2', '0.4', True]\n",
      "0.9173, 0.7058, 0.2170, ['-4.0', '-0.5', '0.5', '0.3', '0.2', True]\n",
      "0.9107, 0.7055, 0.2022, ['-4.0', '-0.5', '0.3', '0.2', '0.5', True]\n",
      "0.9028, 0.6950, 0.2072, ['-6.0', '-0.5', '0.5', '0.2', '0.3', True]\n",
      "0.9026, 0.6927, 0.1993, ['-10.0', '-0.5', '0.5', '0.3', '0.2', True]\n",
      "0.9122, 0.6919, 0.2075, ['-8.0', '-0.5', '0.6', '0.2', '0.2', True]\n",
      "0.9139, 0.6901, 0.2023, ['-8.0', '-0.5', '0.4', '0.3', '0.3', True]\n",
      "0.9004, 0.6888, 0.2146, ['-6.0', '-0.5', '0.6', '0.2', '0.2', True]\n",
      "0.9026, 0.6863, 0.1986, ['-8.0', '-0.5', '0.5', '0.3', '0.2', True]\n",
      "0.9023, 0.6849, 0.1887, ['-6.0', '-0.5', '0.3', '0.2', '0.5', True]\n",
      "dihedral_3Di\n",
      "0.8936, 0.6778, 0.1961, ['-6.0', '-0.5', '0.4', True]\n",
      "0.8910, 0.6684, 0.1928, ['-8.0', '-0.5', '0.3', True]\n",
      "0.9013, 0.6667, 0.1885, ['-10.0', '-0.5', '0.3', True]\n",
      "0.8914, 0.6534, 0.1725, ['-8.0', '-1.0', '0.3', True]\n",
      "0.8931, 0.6534, 0.1863, ['-8.0', '-0.5', '0.4', True]\n",
      "0.8854, 0.6531, 0.1774, ['-12.0', '-0.5', '0.3', True]\n",
      "0.8856, 0.6293, 0.1853, ['-10.0', '-0.5', '0.4', True]\n",
      "dihedral_3Dn\n",
      "0.8996, 0.6933, 0.1774, ['-2.0', '-0.5', '0.7', True]\n",
      "0.8994, 0.6808, 0.1767, ['-4.0', '-0.5', '0.6', True]\n",
      "0.9062, 0.6801, 0.1664, ['-4.0', '-0.5', '0.7', True]\n",
      "0.8837, 0.6729, 0.1705, ['-6.0', '-0.5', '0.6', True]\n",
      "0.8822, 0.6630, 0.1690, ['-6.0', '-0.5', '0.7', True]\n",
      "0.8869, 0.6522, 0.1711, ['-8.0', '-0.5', '0.6', True]\n"
     ]
    }
   ],
   "source": [
    "best_by_method = {}\n",
    "best_params_by_method = {}\n",
    "results_by_method_dict = {}\n",
    "# Iterate over the results dictionary\n",
    "for key, val in results_dict.items():\n",
    "   # if validity_dict[key]:\n",
    "    first_entry = key[0]  # Extract the first part of the key (e.g., 'MI')\n",
    "    if first_entry not in results_by_method_dict:\n",
    "        results_by_method_dict[first_entry] = []\n",
    "    results_by_method_dict[first_entry].append(list(val) + list(key)[1:] + [validity_dict[key]])  # Collect val[0] for this first entry\n",
    "\n",
    "for key, triples in results_by_method_dict.items():\n",
    "    print(key)\n",
    "    sorted_triples = sorted(triples, key=lambda x: x[1], reverse = True)\n",
    "\n",
    "    # Print each triple with values rounded to the 4th decimal\n",
    "    for triple in sorted_triples:\n",
    "        print(f\"{round(triple[0], 4):.4f}, {round(triple[1], 4):.4f}, {round(triple[2], 4):.4f}, {triple[3:]}\")\n",
    "    best_by_method[key]=tuple(sorted_triples[0][:3])\n",
    "    best_params_by_method[key] = tuple(sorted_triples[0][3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "151a5e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3Di_3Dn_dihedral': ('-4.0', '-0.5', '0.4', '0.3', '0.3'),\n",
       " 'dihedral_3Di': ('-6.0', '-0.5', '0.4'),\n",
       " 'dihedral_3Dn': ('-2.0', '-0.5', '0.7')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_by_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d61991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.0 -0.5 0.3\n",
      "-2.0 -0.5 0.7\n"
     ]
    }
   ],
   "source": [
    "# for two alphabets\n",
    "name = {}\n",
    "name[\"3Di\"] = \"3Di\"\n",
    "name[\"aa\"] = \"aa\"\n",
    "name[\"3Dn\"] = \"graph_clusters\"\n",
    "name[\"dihedral\"] = \"dihedral\"\n",
    "\n",
    "data_path = \"/cluster/tufts/pettilab/shared/structure_comparison_data\"\n",
    "ref_path =f\"protein_data/ref_names.csv\"\n",
    "query_list_dir_path = f\"protein_data/test_queries_by_10\"\n",
    "coord_path = \"protein_data/allCACoord.npz\"\n",
    "for alphabet,val in best_params_by_method.items():\n",
    "    if alphabet == \"3Di_3Dn_dihedral\": continue\n",
    "    a1, a2 = alphabet.split('_')\n",
    "    a1 = name[a1]\n",
    "    a2 = name[a2]\n",
    "    p1 = pickle.load(open(f\"{data_path}/alphabets/{a1}_karlin_params.pkl\", \"rb\"))\n",
    "    p2 = pickle.load(open(f\"{data_path}/alphabets/{a2}_karlin_params.pkl\", \"rb\"))\n",
    "    \n",
    "    if alphabet!= \"3Di_aa\":\n",
    "        go,ge,w1 = val\n",
    "        print(go,ge,w1)\n",
    "        w2=1-float(w1)\n",
    "    else:\n",
    "        go,ge,w1, w2 = val\n",
    "    path_to_config = f\"test_search_combos/{alphabet}_{go}_{ge}_{w1}_config\"\n",
    "    with open(path_to_config, 'w') as file:\n",
    "        file.write(f\"data_path: {data_path}\" + '\\n')\n",
    "        file.write(f\"coord_d: {coord_path}\" + '\\n')\n",
    "        file.write(f\"oh_d1: alphabets/{a1}.npz\" +'\\n')\n",
    "        file.write(f\"blosum1: alphabets/{a1}_blosum.npy\" +'\\n')\n",
    "        file.write(f\"oh_d2: alphabets/{a2}.npz\" +'\\n')\n",
    "        file.write(f\"blosum2: alphabets/{a2}_blosum.npy\" +'\\n')\n",
    "        file.write(f\"gap_open: {go}\" + '\\n')\n",
    "        file.write(f\"gap_extend: {ge}\" + '\\n')\n",
    "        file.write(f\"w1: {w1}\" + '\\n')\n",
    "        file.write(f\"w2: {w2}\" + '\\n')\n",
    "        file.write(f\"use_two: True\" + '\\n')\n",
    "        file.write(f\"lam: {p1[\"lam\"]}\" + '\\n')\n",
    "        file.write(f\"k: {p1[\"k\"]}\" + '\\n')\n",
    "        file.write(f\"lam2: {p2[\"lam\"]}\" + '\\n')\n",
    "        file.write(f\"k2: {p2[\"k\"]}\" + '\\n')\n",
    "        file.write(f\"refs: {ref_path}\"+ '\\n')\n",
    "        file.write(f\"query_list_dir: {query_list_dir_path}\"+ '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48ecae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for three alphabets\n",
    "name = {}\n",
    "name[\"3Di\"] = \"3Di\"\n",
    "name[\"aa\"] = \"aa\"\n",
    "name[\"3Dn\"] = \"graph_clusters\"\n",
    "name[\"dihedral\"] = \"dihedral\"\n",
    "data_path = \"/cluster/tufts/pettilab/shared/structure_comparison_data\"\n",
    "\n",
    "ref_path =f\"protein_data/ref_names.csv\"\n",
    "query_list_dir_path = f\"protein_data/test_queries_by_10\"\n",
    "coord_path = \"protein_data/allCACoord.npz\"\n",
    "alphabet = \"3Di_3Dn_dihedral\"\n",
    "a1, a2, a3 = alphabet.split('_')\n",
    "a1 = name[a1]\n",
    "a2 = name[a2]\n",
    "a3 = name[a3]\n",
    "p1 = pickle.load(open(f\"{data_path}/alphabets/{a1}_karlin_params.pkl\", \"rb\"))\n",
    "p2 = pickle.load(open(f\"{data_path}/alphabets/{a2}_karlin_params.pkl\", \"rb\"))\n",
    "p3 = pickle.load(open(f\"{data_path}/alphabets/{a3}_karlin_params.pkl\", \"rb\"))\n",
    "\n",
    "go,ge,w1,w2,w3 = best_params_by_method[alphabet]\n",
    "path_to_config = f\"test_search_combos/{alphabet}_{go}_{ge}_{w1}_{w2}_{w3}_config\"\n",
    "with open(path_to_config, 'w') as file:\n",
    "    file.write(f\"data_path: {data_path}\" + '\\n')\n",
    "    file.write(f\"coord_d: {coord_path}\" + '\\n')\n",
    "    file.write(f\"oh_d1: alphabets/{a1}.npz\" +'\\n')\n",
    "    file.write(f\"blosum1: alphabets/{a1}_blosum.npy\" +'\\n')\n",
    "    file.write(f\"oh_d2: alphabets/{a2}.npz\" +'\\n')\n",
    "    file.write(f\"blosum2: alphabets/{a2}_blosum.npy\" +'\\n')\n",
    "    file.write(f\"oh_d3: alphabets/{a3}.npz\" +'\\n')\n",
    "    file.write(f\"blosum3: alphabets/{a3}_blosum.npy\" +'\\n')\n",
    "    file.write(f\"gap_open: {go}\" + '\\n')\n",
    "    file.write(f\"gap_extend: {ge}\" + '\\n')\n",
    "    file.write(f\"w1: {w1}\" + '\\n')\n",
    "    file.write(f\"w2: {w2}\" + '\\n')\n",
    "    file.write(f\"w3: {w3}\" + '\\n')\n",
    "    file.write(f\"use_three: True\" + '\\n')\n",
    "    file.write(f\"lam: {p1[\"lam\"]}\" + '\\n')\n",
    "    file.write(f\"k: {p1[\"k\"]}\" + '\\n')\n",
    "    file.write(f\"lam2: {p2[\"lam\"]}\" + '\\n')\n",
    "    file.write(f\"k2: {p2[\"k\"]}\" + '\\n')\n",
    "    file.write(f\"lam3: {p3[\"lam\"]}\" + '\\n')\n",
    "    file.write(f\"k3: {p3[\"k\"]}\" + '\\n')\n",
    "    file.write(f\"refs: {ref_path}\"+ '\\n')\n",
    "    file.write(f\"query_list_dir: {query_list_dir_path}\"+ '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cefa7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax3",
   "language": "python",
   "name": "jax3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
